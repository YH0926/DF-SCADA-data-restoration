**1.运行环境**

Linux Python3，

**依赖包：**

numpy, scipy, pickle, xgboost-gpu, lightgbm, sklearn

其中lightgbm使用CPU计算，而xgboost需要使用GPU计算

**目录结构：**

![1552813759590](https://github.com/cheungwoonming/DF-SCADA-data-restoration/tree/master/pic/1552813759590.png)

./data 存放训练数据，dataset放解压数据

./result 存放运行结果



**2.运行代码**

**（1）处理数据**

**命令行运行：**``` python process_data.py``` 

产生结果：合并数据集，构造验证集，聚合数据，构造特征字典等。计算特征相关性要挺久的，可能一个小时。

**（2）训练模型和预测结果**

**模型预测的每条命令可以并行运行，可以在服务器上同时运行加快速度，不需要按顺序**

其中用到了lightgbm模型和randomforest模型都是使用cpu多线程计算的，线程越大计算越快；xgboost模型是用gpu计算的，在代码中指定可用的gpu_id：CUDA_VISIBLE_DEVICES

**a.命令行运行：**```python rule_predict.py```

产生结果：两个插值预测结果和top预测结果

**b.命令行运行：**

```python horizontal_predict.py 20 regression```

```python horizontal_predict.py 20 mape```

```python horizontal_predict_ver.py 20 regression```

```python horizontal_predict_ver.py 20 mape```

```python horizontal_predict_relate.py 20 regression```

```python horizontal_predict_relate.py 20 mape```

```python vertical_predict.py 20 regression```

```python vertical_predict.py 20 mape```

上面是lightgbm模型，20是线程数，cpu多的可以设置得大一点，跑的快一点

```python vertical_predict_rf.py 20```

```python horizontal_predict_ver_rf.py 20```

上面是randomforest模型，20是线程数，cpu多的可以设置得大一点，跑的快一点

```python xgb_horizontal_predict.py 0 ```

```python xgb_horizontal_predict_relate.py 0 ```

```python xgb_horizontal_predict_ver.py 0 ```

```python xgb_vertical_predict.py 0 ```

```python xgb_vertical_predict_hor.py 0 1 ```

```python xgb_vertical_predict_hor.py 0 2 ```

上面是xgboost模型，第一个参数是gpu_id，用于设置CUDA_VISIBLE_DEVICES，可修改，第二个参数是两种不同方法，不需要修改

产生结果：16个模型结果和对应的得分表，每个模型的运行时间大概在1天到2天之间。

其实主要用到的结果是插值的三个结果，xgb_horizontal_predict_relate.py，xgb_horizontal_predict_ver.py，xgb_vertical_predict.py， xgb_vertical_predict_hor.py，xgboost的这四个结果，lightgbm以及其他模型可能是在一小部分风场一小部分特征的结果更好，而作为一个补充。

**（3）合并结果**

在目录 ./result 中生成完所有结果后，运行：

```python process_result.py```

产生结果：会产生很多中间结果，最终提交的最优合并结果文件为：index_nearest_ver_top_hor.csv

